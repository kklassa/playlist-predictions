{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/prepared_data_v3.csv')\n",
    "data.drop(columns=['name_track', 'name_artist', 'release_date', 'genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_track = LabelEncoder()\n",
    "le_artist = LabelEncoder()\n",
    "\n",
    "data['id_track'] = le_track.fit_transform(data['id_track'])\n",
    "data['id_artist'] = le_artist.fit_transform(data['id_artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../artifacts/preprocessing/le_track.pkl', 'wb') as f:\n",
    "    pickle.dump(le_track, f)\n",
    "with open('../artifacts/preprocessing/le_artist.pkl', 'wb') as f:\n",
    "    pickle.dump(le_artist, f)\n",
    "\n",
    "# load with\n",
    "# with open('../artifacts/preprocessing/le_track.pkl', 'rb') as f:\n",
    "#     le_track = pickle.load(f)\n",
    "# with open('../artifacts/preprocessing/le_artist.pkl', 'rb') as f:\n",
    "#     le_artist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_weeks = data['week_number'].max()\n",
    "for week in range(no_weeks):\n",
    "    #data[data['week_number'] == week]['next_week_plays'] = data[data['week_number'] == week+1]['track_plays']\n",
    "    data.loc[data['week_number'] == week, 'next_week_plays'] = data.loc[data['week_number'] == week+1, 'track_plays'].values\n",
    "\n",
    "data['next_week_plays'] = data['next_week_plays'].fillna(0).astype(int)\n",
    "data.drop(columns=['week_number'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data['week_number'] == no_weeks].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalize = ['popularity', 'duration_ms', 'danceability', 'energy', 'key', 'loudness', 'speechiness', \n",
    "                         'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'artist_popularity', \n",
    "                         'track_plays', 'artist_plays']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data[features_to_normalize] = scaler.fit_transform(data[features_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../artifacts/preprocessing/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['next_week_plays'].values\n",
    "X = data.drop('next_week_plays', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float())\n",
    "val_dataset = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).float())\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionPredictor(nn.Module):\n",
    "    def __init__(self, num_features: int) -> None:\n",
    "        super(LinearRegressionPredictor, self).__init__()\n",
    "        self.layer = nn.Linear(num_features, 1)\n",
    "\n",
    "        nn.init.uniform_(self.layer.weight, -0.1, 0.1)\n",
    "        nn.init.constant_(self.layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionPredictor(X_train.shape[1]).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch} loss: {epoch_loss / len(train_loader)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNPredictor(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden) -> None:\n",
    "        super(NNPredictor, self).__init__()\n",
    "        self.input_layer = nn.Linear(num_features, num_hidden)\n",
    "        self.hidden_layer_1 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_layer_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.output_layer = nn.Linear(num_hidden, 1)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        x = self.activation(self.hidden_layer_1(x))\n",
    "        x = self.activation(self.hidden_layer_2(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = NNPredictor(X_train.shape[1], 128).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 3.897562338407429\n",
      "Epoch 1 loss: 1.7935495885485637\n",
      "Epoch 2 loss: 1.290972146829469\n",
      "Epoch 3 loss: 1.1802575443820975\n",
      "Epoch 4 loss: 0.9421254186614527\n",
      "Epoch 5 loss: 0.92620422007754\n",
      "Epoch 6 loss: 0.8395765460225116\n",
      "Epoch 7 loss: 0.7647431578008171\n",
      "Epoch 8 loss: 0.7086922119989825\n",
      "Epoch 9 loss: 0.7086464180387523\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    epoch_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = nn_model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch} loss: {epoch_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  2.540753063680413\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nn_model.eval()\n",
    "y_pred = np.array([])\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(val_loader):\n",
    "        outputs = nn_model(inputs)\n",
    "        y_pred = np.append(y_pred, outputs.squeeze(1).numpy())\n",
    "\n",
    "\n",
    "print('Test RMSE: ', mean_squared_error(y_val, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nn_model.state_dict(), '../artifacts/models/nn_regressor.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, max_depth=6, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kklassa/Code/Uni/IUM/venv/lib/python3.11/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:1.80631\n",
      "[1]\tvalidation_0-rmse:1.79009\n",
      "[2]\tvalidation_0-rmse:1.77406\n",
      "[3]\tvalidation_0-rmse:1.75820\n",
      "[4]\tvalidation_0-rmse:1.74252\n",
      "[5]\tvalidation_0-rmse:1.72702\n",
      "[6]\tvalidation_0-rmse:1.71169\n",
      "[7]\tvalidation_0-rmse:1.69653\n",
      "[8]\tvalidation_0-rmse:1.68154\n",
      "[9]\tvalidation_0-rmse:1.66671\n",
      "[10]\tvalidation_0-rmse:1.65205\n",
      "[11]\tvalidation_0-rmse:1.63756\n",
      "[12]\tvalidation_0-rmse:1.62323\n",
      "[13]\tvalidation_0-rmse:1.60906\n",
      "[14]\tvalidation_0-rmse:1.59505\n",
      "[15]\tvalidation_0-rmse:1.58121\n",
      "[16]\tvalidation_0-rmse:1.56752\n",
      "[17]\tvalidation_0-rmse:1.55399\n",
      "[18]\tvalidation_0-rmse:1.54061\n",
      "[19]\tvalidation_0-rmse:1.52739\n",
      "[20]\tvalidation_0-rmse:1.51431\n",
      "[21]\tvalidation_0-rmse:1.50138\n",
      "[22]\tvalidation_0-rmse:1.48860\n",
      "[23]\tvalidation_0-rmse:1.47597\n",
      "[24]\tvalidation_0-rmse:1.46348\n",
      "[25]\tvalidation_0-rmse:1.45114\n",
      "[26]\tvalidation_0-rmse:1.43893\n",
      "[27]\tvalidation_0-rmse:1.42690\n",
      "[28]\tvalidation_0-rmse:1.41500\n",
      "[29]\tvalidation_0-rmse:1.40324\n",
      "[30]\tvalidation_0-rmse:1.39162\n",
      "[31]\tvalidation_0-rmse:1.38014\n",
      "[32]\tvalidation_0-rmse:1.36879\n",
      "[33]\tvalidation_0-rmse:1.35758\n",
      "[34]\tvalidation_0-rmse:1.34646\n",
      "[35]\tvalidation_0-rmse:1.33550\n",
      "[36]\tvalidation_0-rmse:1.32467\n",
      "[37]\tvalidation_0-rmse:1.31399\n",
      "[38]\tvalidation_0-rmse:1.30340\n",
      "[39]\tvalidation_0-rmse:1.29295\n",
      "[40]\tvalidation_0-rmse:1.28264\n",
      "[41]\tvalidation_0-rmse:1.27242\n",
      "[42]\tvalidation_0-rmse:1.26237\n",
      "[43]\tvalidation_0-rmse:1.25239\n",
      "[44]\tvalidation_0-rmse:1.24256\n",
      "[45]\tvalidation_0-rmse:1.23286\n",
      "[46]\tvalidation_0-rmse:1.22327\n",
      "[47]\tvalidation_0-rmse:1.21380\n",
      "[48]\tvalidation_0-rmse:1.20444\n",
      "[49]\tvalidation_0-rmse:1.19518\n",
      "[50]\tvalidation_0-rmse:1.18610\n",
      "[51]\tvalidation_0-rmse:1.17708\n",
      "[52]\tvalidation_0-rmse:1.16817\n",
      "[53]\tvalidation_0-rmse:1.15937\n",
      "[54]\tvalidation_0-rmse:1.15072\n",
      "[55]\tvalidation_0-rmse:1.14213\n",
      "[56]\tvalidation_0-rmse:1.13367\n",
      "[57]\tvalidation_0-rmse:1.12530\n",
      "[58]\tvalidation_0-rmse:1.11706\n",
      "[59]\tvalidation_0-rmse:1.10890\n",
      "[60]\tvalidation_0-rmse:1.10088\n",
      "[61]\tvalidation_0-rmse:1.09292\n",
      "[62]\tvalidation_0-rmse:1.08508\n",
      "[63]\tvalidation_0-rmse:1.07733\n",
      "[64]\tvalidation_0-rmse:1.06968\n",
      "[65]\tvalidation_0-rmse:1.06216\n",
      "[66]\tvalidation_0-rmse:1.05470\n",
      "[67]\tvalidation_0-rmse:1.04733\n",
      "[68]\tvalidation_0-rmse:1.04007\n",
      "[69]\tvalidation_0-rmse:1.03291\n",
      "[70]\tvalidation_0-rmse:1.02584\n",
      "[71]\tvalidation_0-rmse:1.01885\n",
      "[72]\tvalidation_0-rmse:1.01202\n",
      "[73]\tvalidation_0-rmse:1.00523\n",
      "[74]\tvalidation_0-rmse:0.99853\n",
      "[75]\tvalidation_0-rmse:0.99194\n",
      "[76]\tvalidation_0-rmse:0.98542\n",
      "[77]\tvalidation_0-rmse:0.97901\n",
      "[78]\tvalidation_0-rmse:0.97266\n",
      "[79]\tvalidation_0-rmse:0.96642\n",
      "[80]\tvalidation_0-rmse:0.96021\n",
      "[81]\tvalidation_0-rmse:0.95414\n",
      "[82]\tvalidation_0-rmse:0.94810\n",
      "[83]\tvalidation_0-rmse:0.94219\n",
      "[84]\tvalidation_0-rmse:0.93633\n",
      "[85]\tvalidation_0-rmse:0.93055\n",
      "[86]\tvalidation_0-rmse:0.92489\n",
      "[87]\tvalidation_0-rmse:0.91926\n",
      "[88]\tvalidation_0-rmse:0.91376\n",
      "[89]\tvalidation_0-rmse:0.90829\n",
      "[90]\tvalidation_0-rmse:0.90294\n",
      "[91]\tvalidation_0-rmse:0.89762\n",
      "[92]\tvalidation_0-rmse:0.89242\n",
      "[93]\tvalidation_0-rmse:0.88729\n",
      "[94]\tvalidation_0-rmse:0.88223\n",
      "[95]\tvalidation_0-rmse:0.87725\n",
      "[96]\tvalidation_0-rmse:0.87233\n",
      "[97]\tvalidation_0-rmse:0.86747\n",
      "[98]\tvalidation_0-rmse:0.86266\n",
      "[99]\tvalidation_0-rmse:0.85796\n",
      "[100]\tvalidation_0-rmse:0.85329\n",
      "[101]\tvalidation_0-rmse:0.84871\n",
      "[102]\tvalidation_0-rmse:0.84418\n",
      "[103]\tvalidation_0-rmse:0.83973\n",
      "[104]\tvalidation_0-rmse:0.83534\n",
      "[105]\tvalidation_0-rmse:0.83104\n",
      "[106]\tvalidation_0-rmse:0.82676\n",
      "[107]\tvalidation_0-rmse:0.82255\n",
      "[108]\tvalidation_0-rmse:0.81842\n",
      "[109]\tvalidation_0-rmse:0.81434\n",
      "[110]\tvalidation_0-rmse:0.81033\n",
      "[111]\tvalidation_0-rmse:0.80637\n",
      "[112]\tvalidation_0-rmse:0.80248\n",
      "[113]\tvalidation_0-rmse:0.79864\n",
      "[114]\tvalidation_0-rmse:0.79490\n",
      "[115]\tvalidation_0-rmse:0.79115\n",
      "[116]\tvalidation_0-rmse:0.78748\n",
      "[117]\tvalidation_0-rmse:0.78386\n",
      "[118]\tvalidation_0-rmse:0.78030\n",
      "[119]\tvalidation_0-rmse:0.77680\n",
      "[120]\tvalidation_0-rmse:0.77336\n",
      "[121]\tvalidation_0-rmse:0.76995\n",
      "[122]\tvalidation_0-rmse:0.76660\n",
      "[123]\tvalidation_0-rmse:0.76330\n",
      "[124]\tvalidation_0-rmse:0.76006\n",
      "[125]\tvalidation_0-rmse:0.75689\n",
      "[126]\tvalidation_0-rmse:0.75375\n",
      "[127]\tvalidation_0-rmse:0.75067\n",
      "[128]\tvalidation_0-rmse:0.74762\n",
      "[129]\tvalidation_0-rmse:0.74462\n",
      "[130]\tvalidation_0-rmse:0.74166\n",
      "[131]\tvalidation_0-rmse:0.73876\n",
      "[132]\tvalidation_0-rmse:0.73593\n",
      "[133]\tvalidation_0-rmse:0.73312\n",
      "[134]\tvalidation_0-rmse:0.73034\n",
      "[135]\tvalidation_0-rmse:0.72763\n",
      "[136]\tvalidation_0-rmse:0.72499\n",
      "[137]\tvalidation_0-rmse:0.72234\n",
      "[138]\tvalidation_0-rmse:0.71974\n",
      "[139]\tvalidation_0-rmse:0.71719\n",
      "[140]\tvalidation_0-rmse:0.71470\n",
      "[141]\tvalidation_0-rmse:0.71223\n",
      "[142]\tvalidation_0-rmse:0.70984\n",
      "[143]\tvalidation_0-rmse:0.70746\n",
      "[144]\tvalidation_0-rmse:0.70510\n",
      "[145]\tvalidation_0-rmse:0.70277\n",
      "[146]\tvalidation_0-rmse:0.70053\n",
      "[147]\tvalidation_0-rmse:0.69829\n",
      "[148]\tvalidation_0-rmse:0.69609\n",
      "[149]\tvalidation_0-rmse:0.69393\n",
      "[150]\tvalidation_0-rmse:0.69179\n",
      "[151]\tvalidation_0-rmse:0.68970\n",
      "[152]\tvalidation_0-rmse:0.68768\n",
      "[153]\tvalidation_0-rmse:0.68566\n",
      "[154]\tvalidation_0-rmse:0.68368\n",
      "[155]\tvalidation_0-rmse:0.68175\n",
      "[156]\tvalidation_0-rmse:0.67983\n",
      "[157]\tvalidation_0-rmse:0.67794\n",
      "[158]\tvalidation_0-rmse:0.67608\n",
      "[159]\tvalidation_0-rmse:0.67426\n",
      "[160]\tvalidation_0-rmse:0.67245\n",
      "[161]\tvalidation_0-rmse:0.67070\n",
      "[162]\tvalidation_0-rmse:0.66898\n",
      "[163]\tvalidation_0-rmse:0.66730\n",
      "[164]\tvalidation_0-rmse:0.66563\n",
      "[165]\tvalidation_0-rmse:0.66399\n",
      "[166]\tvalidation_0-rmse:0.66238\n",
      "[167]\tvalidation_0-rmse:0.66079\n",
      "[168]\tvalidation_0-rmse:0.65923\n",
      "[169]\tvalidation_0-rmse:0.65769\n",
      "[170]\tvalidation_0-rmse:0.65621\n",
      "[171]\tvalidation_0-rmse:0.65474\n",
      "[172]\tvalidation_0-rmse:0.65328\n",
      "[173]\tvalidation_0-rmse:0.65185\n",
      "[174]\tvalidation_0-rmse:0.65046\n",
      "[175]\tvalidation_0-rmse:0.64907\n",
      "[176]\tvalidation_0-rmse:0.64772\n",
      "[177]\tvalidation_0-rmse:0.64639\n",
      "[178]\tvalidation_0-rmse:0.64509\n",
      "[179]\tvalidation_0-rmse:0.64380\n",
      "[180]\tvalidation_0-rmse:0.64254\n",
      "[181]\tvalidation_0-rmse:0.64132\n",
      "[182]\tvalidation_0-rmse:0.64010\n",
      "[183]\tvalidation_0-rmse:0.63891\n",
      "[184]\tvalidation_0-rmse:0.63774\n",
      "[185]\tvalidation_0-rmse:0.63660\n",
      "[186]\tvalidation_0-rmse:0.63546\n",
      "[187]\tvalidation_0-rmse:0.63434\n",
      "[188]\tvalidation_0-rmse:0.63324\n",
      "[189]\tvalidation_0-rmse:0.63217\n",
      "[190]\tvalidation_0-rmse:0.63111\n",
      "[191]\tvalidation_0-rmse:0.63009\n",
      "[192]\tvalidation_0-rmse:0.62910\n",
      "[193]\tvalidation_0-rmse:0.62810\n",
      "[194]\tvalidation_0-rmse:0.62713\n",
      "[195]\tvalidation_0-rmse:0.62618\n",
      "[196]\tvalidation_0-rmse:0.62525\n",
      "[197]\tvalidation_0-rmse:0.62433\n",
      "[198]\tvalidation_0-rmse:0.62342\n",
      "[199]\tvalidation_0-rmse:0.62254\n",
      "[200]\tvalidation_0-rmse:0.62167\n",
      "[201]\tvalidation_0-rmse:0.62080\n",
      "[202]\tvalidation_0-rmse:0.61997\n",
      "[203]\tvalidation_0-rmse:0.61914\n",
      "[204]\tvalidation_0-rmse:0.61831\n",
      "[205]\tvalidation_0-rmse:0.61750\n",
      "[206]\tvalidation_0-rmse:0.61672\n",
      "[207]\tvalidation_0-rmse:0.61594\n",
      "[208]\tvalidation_0-rmse:0.61519\n",
      "[209]\tvalidation_0-rmse:0.61446\n",
      "[210]\tvalidation_0-rmse:0.61374\n",
      "[211]\tvalidation_0-rmse:0.61304\n",
      "[212]\tvalidation_0-rmse:0.61234\n",
      "[213]\tvalidation_0-rmse:0.61165\n",
      "[214]\tvalidation_0-rmse:0.61098\n",
      "[215]\tvalidation_0-rmse:0.61031\n",
      "[216]\tvalidation_0-rmse:0.60966\n",
      "[217]\tvalidation_0-rmse:0.60903\n",
      "[218]\tvalidation_0-rmse:0.60840\n",
      "[219]\tvalidation_0-rmse:0.60777\n",
      "[220]\tvalidation_0-rmse:0.60716\n",
      "[221]\tvalidation_0-rmse:0.60656\n",
      "[222]\tvalidation_0-rmse:0.60598\n",
      "[223]\tvalidation_0-rmse:0.60540\n",
      "[224]\tvalidation_0-rmse:0.60483\n",
      "[225]\tvalidation_0-rmse:0.60428\n",
      "[226]\tvalidation_0-rmse:0.60375\n",
      "[227]\tvalidation_0-rmse:0.60321\n",
      "[228]\tvalidation_0-rmse:0.60270\n",
      "[229]\tvalidation_0-rmse:0.60219\n",
      "[230]\tvalidation_0-rmse:0.60168\n",
      "[231]\tvalidation_0-rmse:0.60122\n",
      "[232]\tvalidation_0-rmse:0.60073\n",
      "[233]\tvalidation_0-rmse:0.60027\n",
      "[234]\tvalidation_0-rmse:0.59983\n",
      "[235]\tvalidation_0-rmse:0.59936\n",
      "[236]\tvalidation_0-rmse:0.59891\n",
      "[237]\tvalidation_0-rmse:0.59850\n",
      "[238]\tvalidation_0-rmse:0.59808\n",
      "[239]\tvalidation_0-rmse:0.59768\n",
      "[240]\tvalidation_0-rmse:0.59726\n",
      "[241]\tvalidation_0-rmse:0.59684\n",
      "[242]\tvalidation_0-rmse:0.59646\n",
      "[243]\tvalidation_0-rmse:0.59608\n",
      "[244]\tvalidation_0-rmse:0.59572\n",
      "[245]\tvalidation_0-rmse:0.59535\n",
      "[246]\tvalidation_0-rmse:0.59500\n",
      "[247]\tvalidation_0-rmse:0.59466\n",
      "[248]\tvalidation_0-rmse:0.59431\n",
      "[249]\tvalidation_0-rmse:0.59396\n",
      "[250]\tvalidation_0-rmse:0.59364\n",
      "[251]\tvalidation_0-rmse:0.59332\n",
      "[252]\tvalidation_0-rmse:0.59300\n",
      "[253]\tvalidation_0-rmse:0.59268\n",
      "[254]\tvalidation_0-rmse:0.59235\n",
      "[255]\tvalidation_0-rmse:0.59206\n",
      "[256]\tvalidation_0-rmse:0.59177\n",
      "[257]\tvalidation_0-rmse:0.59148\n",
      "[258]\tvalidation_0-rmse:0.59119\n",
      "[259]\tvalidation_0-rmse:0.59091\n",
      "[260]\tvalidation_0-rmse:0.59062\n",
      "[261]\tvalidation_0-rmse:0.59034\n",
      "[262]\tvalidation_0-rmse:0.59007\n",
      "[263]\tvalidation_0-rmse:0.58982\n",
      "[264]\tvalidation_0-rmse:0.58957\n",
      "[265]\tvalidation_0-rmse:0.58931\n",
      "[266]\tvalidation_0-rmse:0.58906\n",
      "[267]\tvalidation_0-rmse:0.58884\n",
      "[268]\tvalidation_0-rmse:0.58861\n",
      "[269]\tvalidation_0-rmse:0.58837\n",
      "[270]\tvalidation_0-rmse:0.58814\n",
      "[271]\tvalidation_0-rmse:0.58791\n",
      "[272]\tvalidation_0-rmse:0.58769\n",
      "[273]\tvalidation_0-rmse:0.58749\n",
      "[274]\tvalidation_0-rmse:0.58727\n",
      "[275]\tvalidation_0-rmse:0.58707\n",
      "[276]\tvalidation_0-rmse:0.58686\n",
      "[277]\tvalidation_0-rmse:0.58663\n",
      "[278]\tvalidation_0-rmse:0.58644\n",
      "[279]\tvalidation_0-rmse:0.58623\n",
      "[280]\tvalidation_0-rmse:0.58607\n",
      "[281]\tvalidation_0-rmse:0.58587\n",
      "[282]\tvalidation_0-rmse:0.58569\n",
      "[283]\tvalidation_0-rmse:0.58549\n",
      "[284]\tvalidation_0-rmse:0.58532\n",
      "[285]\tvalidation_0-rmse:0.58515\n",
      "[286]\tvalidation_0-rmse:0.58497\n",
      "[287]\tvalidation_0-rmse:0.58480\n",
      "[288]\tvalidation_0-rmse:0.58465\n",
      "[289]\tvalidation_0-rmse:0.58449\n",
      "[290]\tvalidation_0-rmse:0.58433\n",
      "[291]\tvalidation_0-rmse:0.58417\n",
      "[292]\tvalidation_0-rmse:0.58404\n",
      "[293]\tvalidation_0-rmse:0.58390\n",
      "[294]\tvalidation_0-rmse:0.58375\n",
      "[295]\tvalidation_0-rmse:0.58360\n",
      "[296]\tvalidation_0-rmse:0.58347\n",
      "[297]\tvalidation_0-rmse:0.58333\n",
      "[298]\tvalidation_0-rmse:0.58319\n",
      "[299]\tvalidation_0-rmse:0.58306\n",
      "[300]\tvalidation_0-rmse:0.58294\n",
      "[301]\tvalidation_0-rmse:0.58282\n",
      "[302]\tvalidation_0-rmse:0.58270\n",
      "[303]\tvalidation_0-rmse:0.58257\n",
      "[304]\tvalidation_0-rmse:0.58246\n",
      "[305]\tvalidation_0-rmse:0.58234\n",
      "[306]\tvalidation_0-rmse:0.58222\n",
      "[307]\tvalidation_0-rmse:0.58210\n",
      "[308]\tvalidation_0-rmse:0.58197\n",
      "[309]\tvalidation_0-rmse:0.58186\n",
      "[310]\tvalidation_0-rmse:0.58177\n",
      "[311]\tvalidation_0-rmse:0.58168\n",
      "[312]\tvalidation_0-rmse:0.58159\n",
      "[313]\tvalidation_0-rmse:0.58148\n",
      "[314]\tvalidation_0-rmse:0.58139\n",
      "[315]\tvalidation_0-rmse:0.58129\n",
      "[316]\tvalidation_0-rmse:0.58118\n",
      "[317]\tvalidation_0-rmse:0.58108\n",
      "[318]\tvalidation_0-rmse:0.58099\n",
      "[319]\tvalidation_0-rmse:0.58090\n",
      "[320]\tvalidation_0-rmse:0.58081\n",
      "[321]\tvalidation_0-rmse:0.58072\n",
      "[322]\tvalidation_0-rmse:0.58063\n",
      "[323]\tvalidation_0-rmse:0.58054\n",
      "[324]\tvalidation_0-rmse:0.58045\n",
      "[325]\tvalidation_0-rmse:0.58036\n",
      "[326]\tvalidation_0-rmse:0.58029\n",
      "[327]\tvalidation_0-rmse:0.58021\n",
      "[328]\tvalidation_0-rmse:0.58013\n",
      "[329]\tvalidation_0-rmse:0.58005\n",
      "[330]\tvalidation_0-rmse:0.57996\n",
      "[331]\tvalidation_0-rmse:0.57988\n",
      "[332]\tvalidation_0-rmse:0.57981\n",
      "[333]\tvalidation_0-rmse:0.57976\n",
      "[334]\tvalidation_0-rmse:0.57969\n",
      "[335]\tvalidation_0-rmse:0.57961\n",
      "[336]\tvalidation_0-rmse:0.57956\n",
      "[337]\tvalidation_0-rmse:0.57949\n",
      "[338]\tvalidation_0-rmse:0.57943\n",
      "[339]\tvalidation_0-rmse:0.57936\n",
      "[340]\tvalidation_0-rmse:0.57931\n",
      "[341]\tvalidation_0-rmse:0.57927\n",
      "[342]\tvalidation_0-rmse:0.57923\n",
      "[343]\tvalidation_0-rmse:0.57917\n",
      "[344]\tvalidation_0-rmse:0.57912\n",
      "[345]\tvalidation_0-rmse:0.57908\n",
      "[346]\tvalidation_0-rmse:0.57903\n",
      "[347]\tvalidation_0-rmse:0.57896\n",
      "[348]\tvalidation_0-rmse:0.57891\n",
      "[349]\tvalidation_0-rmse:0.57886\n",
      "[350]\tvalidation_0-rmse:0.57880\n",
      "[351]\tvalidation_0-rmse:0.57876\n",
      "[352]\tvalidation_0-rmse:0.57872\n",
      "[353]\tvalidation_0-rmse:0.57868\n",
      "[354]\tvalidation_0-rmse:0.57863\n",
      "[355]\tvalidation_0-rmse:0.57857\n",
      "[356]\tvalidation_0-rmse:0.57854\n",
      "[357]\tvalidation_0-rmse:0.57850\n",
      "[358]\tvalidation_0-rmse:0.57842\n",
      "[359]\tvalidation_0-rmse:0.57839\n",
      "[360]\tvalidation_0-rmse:0.57832\n",
      "[361]\tvalidation_0-rmse:0.57828\n",
      "[362]\tvalidation_0-rmse:0.57821\n",
      "[363]\tvalidation_0-rmse:0.57817\n",
      "[364]\tvalidation_0-rmse:0.57814\n",
      "[365]\tvalidation_0-rmse:0.57808\n",
      "[366]\tvalidation_0-rmse:0.57804\n",
      "[367]\tvalidation_0-rmse:0.57801\n",
      "[368]\tvalidation_0-rmse:0.57797\n",
      "[369]\tvalidation_0-rmse:0.57795\n",
      "[370]\tvalidation_0-rmse:0.57792\n",
      "[371]\tvalidation_0-rmse:0.57789\n",
      "[372]\tvalidation_0-rmse:0.57786\n",
      "[373]\tvalidation_0-rmse:0.57782\n",
      "[374]\tvalidation_0-rmse:0.57780\n",
      "[375]\tvalidation_0-rmse:0.57777\n",
      "[376]\tvalidation_0-rmse:0.57773\n",
      "[377]\tvalidation_0-rmse:0.57769\n",
      "[378]\tvalidation_0-rmse:0.57767\n",
      "[379]\tvalidation_0-rmse:0.57764\n",
      "[380]\tvalidation_0-rmse:0.57759\n",
      "[381]\tvalidation_0-rmse:0.57757\n",
      "[382]\tvalidation_0-rmse:0.57756\n",
      "[383]\tvalidation_0-rmse:0.57754\n",
      "[384]\tvalidation_0-rmse:0.57749\n",
      "[385]\tvalidation_0-rmse:0.57746\n",
      "[386]\tvalidation_0-rmse:0.57741\n",
      "[387]\tvalidation_0-rmse:0.57737\n",
      "[388]\tvalidation_0-rmse:0.57733\n",
      "[389]\tvalidation_0-rmse:0.57730\n",
      "[390]\tvalidation_0-rmse:0.57727\n",
      "[391]\tvalidation_0-rmse:0.57724\n",
      "[392]\tvalidation_0-rmse:0.57721\n",
      "[393]\tvalidation_0-rmse:0.57718\n",
      "[394]\tvalidation_0-rmse:0.57715\n",
      "[395]\tvalidation_0-rmse:0.57711\n",
      "[396]\tvalidation_0-rmse:0.57708\n",
      "[397]\tvalidation_0-rmse:0.57704\n",
      "[398]\tvalidation_0-rmse:0.57701\n",
      "[399]\tvalidation_0-rmse:0.57700\n",
      "[400]\tvalidation_0-rmse:0.57700\n",
      "[401]\tvalidation_0-rmse:0.57700\n",
      "[402]\tvalidation_0-rmse:0.57697\n",
      "[403]\tvalidation_0-rmse:0.57693\n",
      "[404]\tvalidation_0-rmse:0.57687\n",
      "[405]\tvalidation_0-rmse:0.57688\n",
      "[406]\tvalidation_0-rmse:0.57686\n",
      "[407]\tvalidation_0-rmse:0.57683\n",
      "[408]\tvalidation_0-rmse:0.57681\n",
      "[409]\tvalidation_0-rmse:0.57678\n",
      "[410]\tvalidation_0-rmse:0.57679\n",
      "[411]\tvalidation_0-rmse:0.57677\n",
      "[412]\tvalidation_0-rmse:0.57676\n",
      "[413]\tvalidation_0-rmse:0.57674\n",
      "[414]\tvalidation_0-rmse:0.57672\n",
      "[415]\tvalidation_0-rmse:0.57671\n",
      "[416]\tvalidation_0-rmse:0.57671\n",
      "[417]\tvalidation_0-rmse:0.57669\n",
      "[418]\tvalidation_0-rmse:0.57666\n",
      "[419]\tvalidation_0-rmse:0.57666\n",
      "[420]\tvalidation_0-rmse:0.57663\n",
      "[421]\tvalidation_0-rmse:0.57659\n",
      "[422]\tvalidation_0-rmse:0.57658\n",
      "[423]\tvalidation_0-rmse:0.57655\n",
      "[424]\tvalidation_0-rmse:0.57652\n",
      "[425]\tvalidation_0-rmse:0.57652\n",
      "[426]\tvalidation_0-rmse:0.57648\n",
      "[427]\tvalidation_0-rmse:0.57648\n",
      "[428]\tvalidation_0-rmse:0.57646\n",
      "[429]\tvalidation_0-rmse:0.57646\n",
      "[430]\tvalidation_0-rmse:0.57644\n",
      "[431]\tvalidation_0-rmse:0.57643\n",
      "[432]\tvalidation_0-rmse:0.57640\n",
      "[433]\tvalidation_0-rmse:0.57638\n",
      "[434]\tvalidation_0-rmse:0.57639\n",
      "[435]\tvalidation_0-rmse:0.57636\n",
      "[436]\tvalidation_0-rmse:0.57635\n",
      "[437]\tvalidation_0-rmse:0.57631\n",
      "[438]\tvalidation_0-rmse:0.57629\n",
      "[439]\tvalidation_0-rmse:0.57628\n",
      "[440]\tvalidation_0-rmse:0.57627\n",
      "[441]\tvalidation_0-rmse:0.57625\n",
      "[442]\tvalidation_0-rmse:0.57624\n",
      "[443]\tvalidation_0-rmse:0.57625\n",
      "[444]\tvalidation_0-rmse:0.57623\n",
      "[445]\tvalidation_0-rmse:0.57621\n",
      "[446]\tvalidation_0-rmse:0.57620\n",
      "[447]\tvalidation_0-rmse:0.57618\n",
      "[448]\tvalidation_0-rmse:0.57616\n",
      "[449]\tvalidation_0-rmse:0.57616\n",
      "[450]\tvalidation_0-rmse:0.57615\n",
      "[451]\tvalidation_0-rmse:0.57613\n",
      "[452]\tvalidation_0-rmse:0.57613\n",
      "[453]\tvalidation_0-rmse:0.57613\n",
      "[454]\tvalidation_0-rmse:0.57614\n",
      "[455]\tvalidation_0-rmse:0.57613\n",
      "[456]\tvalidation_0-rmse:0.57611\n",
      "[457]\tvalidation_0-rmse:0.57610\n",
      "[458]\tvalidation_0-rmse:0.57609\n",
      "[459]\tvalidation_0-rmse:0.57608\n",
      "[460]\tvalidation_0-rmse:0.57606\n",
      "[461]\tvalidation_0-rmse:0.57604\n",
      "[462]\tvalidation_0-rmse:0.57607\n",
      "[463]\tvalidation_0-rmse:0.57607\n",
      "[464]\tvalidation_0-rmse:0.57608\n",
      "[465]\tvalidation_0-rmse:0.57606\n",
      "[466]\tvalidation_0-rmse:0.57606\n",
      "[467]\tvalidation_0-rmse:0.57606\n",
      "[468]\tvalidation_0-rmse:0.57606\n",
      "[469]\tvalidation_0-rmse:0.57606\n",
      "[470]\tvalidation_0-rmse:0.57606\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  0.5794197154325186\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print('Test RMSE: ', mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Path('../artifacts/models/xgb_regressor.model')\n",
    "xgb_model.save_model(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00739053 0.6772501  0.5968689  0.10253602 0.00555139 0.00811028\n",
      " 0.00684761 0.7391458  0.00846094 0.00596823]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drivers license - most popular song\n",
    "original_id = '7lPN2DXiMsVn7XUKtOW1CS'\n",
    "\n",
    "encoded_id = le_track.transform([original_id])[0]\n",
    "\n",
    "matching_rows = data[data['id_track'] == encoded_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint = matching_rows.iloc[0].values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24.0818])\n"
     ]
    }
   ],
   "source": [
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = nn_model(torch.from_numpy(datapoint).float())\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
